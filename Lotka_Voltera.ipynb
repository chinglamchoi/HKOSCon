{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write and Document Benchmark Examples for NeuralNetDiffEq.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using OrdinaryDiffEq, NeuralNetDiffEq, Plots, Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Lotka-Voltera \n",
    "The Lotka-Volterra equations, also the predator-prey equations, models changes in population of prey and predator over time when they interact. This is an example of a first-order nonlinear coupled differential equations, described as:\n",
    "\n",
    "$$\\frac{dx}{dt}=\\alpha x -\\beta x y, \\; \\frac{dy}{dt}=\\delta x y-\\gamma y$$\n",
    "where \n",
    "$x$ and $y$ are the prey and predator populations; $\\frac{dx}{dt}$ and $\\frac{dy}{dt}$ denote instantaneous growth rates. This interaction is parameterised by positive real parameters $\\alpha, \\beta, \\gamma, \\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f(du,u,p,t)\n",
    "  du[1] = p[1]*u[1] - p[2]*u[1]*u[2]\n",
    "  du[2] = -p[3]*u[2] + p[4]*u[1]*u[2]\n",
    "end\n",
    "function f(u,p,t)\n",
    "  [p[1]*u[1] - p[2]*u[1]*u[2],-p[3]*u[2] + p[4]*u[1]*u[2]]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mODEProblem\u001b[0m with uType \u001b[36mArray{Float32,1}\u001b[0m and tType \u001b[36mFloat32\u001b[0m. In-place: \u001b[36mfalse\u001b[0m\n",
       "timespan: (0.0f0, 3.0f0)\n",
       "u0: Float32[1.0, 1.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Float32[1.5,1.0,3.0,1.0]\n",
    "u0 = Float32[1.0,1.0]\n",
    "prob = ODEProblem(f,u0,(0f0,3f0),p)\n",
    "prob_oop = ODEProblem{false}(f,u0,(0f0,3f0),p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Model and Optimiser\n",
    "After many experiments, Adam and NADAM optimiser (with eta=1e-03) tend to outperform others, achieveing a loss as low as 44.6 in 100 epochs. All methods plateau after this loss, if it is reached at all. Larger models with up to 4096 channels tend to plateau at 51 loss within 100 iterations, while smaller models fail to achieve this accuracy. MaxPool layers do not seem to add value to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(#3, MaxPool((1,), pad = (0, 0), stride = (1,)), Conv((1,), 1=>16, relu), Conv((1,), 16=>16, relu), Conv((1,), 16=>32, relu), Conv((1,), 32=>64, relu), Conv((1,), 64=>256, relu), Conv((1,), 256=>256, relu), Conv((1,), 256=>1028, relu), Conv((1,), 1028=>1028), #4, Dense(1028, 512, tanh), Dense(512, 128, relu), Dense(128, 64, tanh), Dense(64, 2), softmax)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sol = solve(prob,Tsit5())\n",
    "\n",
    "opt = ADAM(1e-03) #1e-04\n",
    "# opt = NADAM()\n",
    "# opt = Nesterov()\n",
    "# opt = AMSGrad()\n",
    "# chain = Chain(x -> reshape(x, length(x), 1, 1), Conv((1,), 1=>16, relu), Conv((1,), 16=>8, relu), x -> reshape(x, :, size(x, 4)), Dense(8, 10), softmax)\n",
    "\n",
    "\n",
    "chain = Chain(\n",
    "    x -> reshape(x, length(x), 1, 1), \n",
    "    MaxPool((1,)), \n",
    "    Conv((1,), 1=>16, relu), \n",
    "    Conv((1,), 16=>16, relu), \n",
    "    Conv((1,), 16=>32, relu), \n",
    "    Conv((1,), 32=>64, relu), \n",
    "    Conv((1,), 64=>256, relu), \n",
    "    Conv((1,), 256=>256, relu), \n",
    "    Conv((1,), 256=>1028, relu), \n",
    "    Conv((1,), 1028=>1028), \n",
    "    x -> reshape(x, :, size(x, 4)), \n",
    "    Dense(1028, 512, tanh), \n",
    "    Dense(512, 128, relu), \n",
    "    Dense(128, 64, tanh), \n",
    "    Dense(64, 2), \n",
    "    softmax)\n",
    "\n",
    "# m = Chain(Conv((1,), 1=>16, relu), Conv((1,), 16=>8, relu), x -> reshape(x, :, size(x, 4)), Dense(16, length(u0)), softmax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is: 402.70865\n",
      "Current loss is: 134.39284\n",
      "Current loss is: 74.71057\n",
      "Current loss is: 57.470463\n",
      "Current loss is: 53.17737\n",
      "Current loss is: 52.367645\n",
      "Current loss is: 52.21946\n",
      "Current loss is: 52.1955\n",
      "Current loss is: 52.17527\n",
      "Current loss is: 52.19066\n",
      "Current loss is: 52.1906\n",
      "Current loss is: 52.180058\n",
      "Current loss is: 52.181484\n",
      "Current loss is: 52.180534\n",
      "Current loss is: 52.186043\n",
      "Current loss is: 52.17969\n",
      "Current loss is: 52.181576\n",
      "Current loss is: 52.193066\n",
      "Current loss is: 52.188477\n",
      "Current loss is: 52.203316\n",
      "Current loss is: 52.18\n",
      "Current loss is: 52.179367\n",
      "Current loss is: 52.178936\n",
      "Current loss is: 52.180885\n",
      "Current loss is: 52.178772\n",
      "Current loss is: 52.17996\n",
      "Current loss is: 52.171608\n",
      "Current loss is: 52.186348\n",
      "Current loss is: 52.177525\n",
      "Current loss is: 52.176796\n",
      "Current loss is: 52.178925\n",
      "Current loss is: 52.17926\n",
      "Current loss is: 52.17619\n",
      "Current loss is: 52.179497\n",
      "Current loss is: 52.18814\n",
      "Current loss is: 52.174843\n",
      "Current loss is: 52.17905\n",
      "Current loss is: 52.17587\n",
      "Current loss is: 52.176563\n",
      "Current loss is: 52.17983\n",
      "Current loss is: 52.183487\n",
      "Current loss is: 52.17455\n",
      "Current loss is: 52.187286\n",
      "Current loss is: 52.17991\n",
      "Current loss is: 52.175037\n",
      "Current loss is: 52.17422\n",
      "Current loss is: 52.173195\n",
      "Current loss is: 52.178265\n",
      "Current loss is: 52.180428\n",
      "Current loss is: 52.177723\n",
      "Current loss is: 52.177166\n",
      "Current loss is: 52.171776\n",
      "Current loss is: 52.184044\n",
      "Current loss is: 52.178387\n",
      "Current loss is: 52.17224\n",
      "Current loss is: 52.17301\n",
      "Current loss is: 52.18593\n",
      "Current loss is: 52.172256\n",
      "Current loss is: 52.174118\n",
      "Current loss is: 52.173397\n",
      "Current loss is: 52.16763\n",
      "Current loss is: 52.164017\n",
      "Current loss is: 52.167656\n"
     ]
    }
   ],
   "source": [
    "sol  = solve(prob_oop,NeuralNetDiffEq.NNODE(chain,opt),maxiters = 100, verbose = true, dt=1/5f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(true_sol)\n",
    "plot!(sol)\n",
    "# savefig(\"ADAM.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
